{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hw4.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KxWz6n4fVnsD",
        "colab_type": "text"
      },
      "source": [
        "0. General concepts (for instance, what is artificial intelligence, machine learning, deep learning)\n",
        "\n",
        "\n",
        "This class made me understand how deep artificial intelligence goes.  There are many sub sections to artificial intelligence, such as deep learning and machine learning. These subsections make artificial intelligence the most interesting topic I have learned in my college career. The thing I most got out of this class was Neural Networks and the way they learn."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fBBcqWcJWx7i",
        "colab_type": "text"
      },
      "source": [
        "1. Building a model (for instance, here you can talk about the structure of a convent, what it components are etc.)\n",
        "\n",
        "A neural network is composed of multiple layers. With each layer the learning rate changes based on the previous weights. With N layers, each layer changes the weights and when it goes on to the next layer, the weights are modified. An easy problem gets low weight since it has been solved multiple times. The harder the problem the higher the weight. I think of it as a Bitcoin. The less Bitcoin available, the harder it gets to solve this problem. This structure is vital to a machine learning process and to neural networks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QC_-_NXvXEkM",
        "colab_type": "text"
      },
      "source": [
        "2. Comping a model (for instance, you can talk here about optimizers, learning rate etc.)\n",
        "\n",
        "One of the most important things i learned about in this class is neural networks and they way they learn. The most important concept to me was if the neural network trains too fast and skips its way to descent. With too big of a learning rate our neural network may never reach its minimmum. This is an important concept to our Neueral Networks. As described above, the weights are updated by the optimizer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32-b43Bekomb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Example of optimizer\n",
        "model.load_weights(weights_path)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizers.RMSprop(lr=learning_rate, decay=lr_decay), metrics=['acc'])\n",
        "model.save(os.path.join(models_path, 'pretrained.h5'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5oDOuuj3YuPV",
        "colab_type": "text"
      },
      "source": [
        "3. Training a model (for instance, you can talk about overfitting/underfitting)\n",
        "\n",
        "Over fitting is when a data set is is trained really well but poor results in general cases and other data. On a graph overfitting would be if a line of best fit was trying to get every possible point. On the otherhand, underfitting is when the performance is poor on a training data and poor as well on the general data case. The graph for underfitting looks like it doesn't follow the data set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-686vSeZkLdf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#This is what training looks like\n",
        "epochs = 20\n",
        "history = model.fit(train_images, \n",
        "                      train_labels, \n",
        "                      epochs=epochs,  \n",
        "                      validation_data=(test_images, test_labels))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3nEuu0bscFIs",
        "colab_type": "text"
      },
      "source": [
        "4.  Finetuning  a pretrained model (describe how you proceed)\n",
        "\n",
        "My understanding of finetuning is adding the pretrained layers before your layers of the network. This will allow the network to learn more when it reaches the final layers that you implemented. This can be done on any model that has been pretrained. There is also the option to freeze or not freeze."
      ]
    }
  ]
}